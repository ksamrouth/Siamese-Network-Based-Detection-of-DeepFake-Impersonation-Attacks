{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pairs preparation and the VGG16 with Siamese model (with the VGG16 imported from tensorflow.keras.applications)"
      ],
      "metadata": {
        "id": "51_y8_rxIlex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the needed libraries\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten, BatchNormalization, Conv2D, MaxPool2D, Activation\n",
        "from keras.models import Sequential, Model\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import Recall, Precision\n",
        "from tensorflow.keras.applications import VGG16"
      ],
      "metadata": {
        "id": "oXhv9tC2KC-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qmDhrC45MN-v"
      },
      "outputs": [],
      "source": [
        "def read_jpeg_image(filename):\n",
        "    # Open the image file\n",
        "    img = Image.open(filename)\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the path of the folder containing the genuine and fake folders of each person\n",
        "path=path_of_folder"
      ],
      "metadata": {
        "id": "7D_dWTsEOj2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDb-jMXig3tQ"
      },
      "source": [
        "To read genuine images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DWuSZna-V_8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "n = number_of_persons\n",
        "folder_paths = [f\"path\"+\"/person{i}/original\" for i in range(0, n)]\n",
        "original_files = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    original_files.append(os.listdir(folder_path))\n",
        "    print(folder_path)\n",
        "\n",
        "for file in original_files:\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HKNAbbTg80I"
      },
      "source": [
        "To read fakes images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "loNsZmdxhIZA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "n = number_of_persons\n",
        "folder_paths = [f\"path\"+\"/person{i}/Deepfakes_1\" for i in range(0, n)]\n",
        "deepfakes1_files = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    deepfakes1_files.append(os.listdir(folder_path))\n",
        "    print(folder_path)\n",
        "for file in deepfakes1_files:\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JYX5KK6ThJZm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "n = number_of_persons\n",
        "folder_paths = [f\"path\"+\"/person{i}/Deepfakes_2\" for i in range(0,n)]\n",
        "deepfakes2_files = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    deepfakes2_files.append(os.listdir(folder_path))\n",
        "    print(folder_path)\n",
        "for file in deepfakes2_files:\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "n = number_of_persons\n",
        "folder_paths = [f\"path\"+\"/person{i}/Face2Face_1\" for i in range(0, n)]\n",
        "face2face1_files = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    face2face1_files.append(os.listdir(folder_path))\n",
        "    print(folder_path)\n",
        "for file in face2face1_files:\n",
        "    print(file)"
      ],
      "metadata": {
        "id": "2HlwzbaGLuep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1H5cHXTkhKlI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "n = number_of_persons\n",
        "folder_paths = [f\"path\"+\"/person{i}/Face2Face_2\" for i in range(0, n)]\n",
        "face2face2_files = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    face2face2_files.append(os.listdir(folder_path))\n",
        "    print(folder_path)\n",
        "for file in face2face2_files:\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkPUkpEjhMiW"
      },
      "source": [
        "To make the pairs:\n",
        "\n",
        "Genuine pairs consist of two genuine images of a person. Fake pairs consist of two images of a person: one genuine and one fake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D_ltldzZMjMB"
      },
      "outputs": [],
      "source": [
        "#number_of_pairs = number_of_genuine_pairs = number_of_fake_pairs\n",
        "total_sample_size= number_of_pairs\n",
        "path = path_of_folder\n",
        "np = number_of_images\n",
        "n = number_of_persons\n",
        "def get_data( total_sample_size):\n",
        "    #read the image\n",
        "    image = read_jpeg_image(filename='path'+'/person0/original/1.jpg')\n",
        "    #get the size\n",
        "    dim1 = image.shape[0]\n",
        "    dim2 = image.shape[1]\n",
        "    dim3 = image.shape[2]\n",
        "\n",
        "    genuine_count=0\n",
        "\n",
        "    #to initialize the numpy array with the shape of [total_sample_size, 2, dim1, dim2]\n",
        "    x_geuine_pair = np.zeros([total_sample_size, 2, image.shape[0] ,image.shape[1],3])  # 2 for pairs\n",
        "    y_genuine = np.zeros([total_sample_size, 1])\n",
        "    fake_count=0\n",
        "    x_fake_pair = np.zeros([total_sample_size, 2, image.shape[0] ,image.shape[1],3])  # 2 for pairs\n",
        "    y_fake = np.zeros([total_sample_size, 1])\n",
        "#for first set of genuine pairs\n",
        "    for i in range (n):\n",
        "        for j in range (np):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          x_geuine_pair[genuine_count, 0 ] = img1\n",
        "          x_geuine_pair[genuine_count, 1] = img2\n",
        "          y_genuine[genuine_count] = 1\n",
        "          genuine_count+=1\n",
        "    #for first set of fake pairs (using genuine and Deepfakes_1)\n",
        "    for i in range (n):\n",
        "        for j in range (np):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/Deepfakes_1/'+ deepfakes1_files[i][j])\n",
        "          x_fake_pair[fake_count, 0 ] = img1\n",
        "          x_fake_pair[fake_count, 1] = img2\n",
        "          y_fake[fake_count] = 0\n",
        "          fake_count+=1\n",
        "\n",
        "      #for second set of genuine pairs\n",
        "    for i in range (n):\n",
        "        for j in range (np-1):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j+1])\n",
        "          x_geuine_pair[genuine_count, 0 ] = img1\n",
        "          x_geuine_pair[genuine_count, 1] = img2\n",
        "          y_genuine[genuine_count] = 1\n",
        "          genuine_count+=1\n",
        "    #for second set of fake pairs (using genuine and Deepfakes_2)\n",
        "    for i in range (n):\n",
        "        for j in range (np-1):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/Deepfakes_2/'+ deepfakes2_files[i][j])\n",
        "          x_fake_pair[fake_count, 0 ] = img1\n",
        "          x_fake_pair[fake_count, 1] = img2\n",
        "          y_fake[fake_count] = 0\n",
        "          fake_count+=1\n",
        "    #for third set of genuine pairs\n",
        "    for i in range (n):\n",
        "        for j in range (np-3):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j+3])\n",
        "          x_geuine_pair[genuine_count, 0 ] = img1\n",
        "          x_geuine_pair[genuine_count, 1] = img2\n",
        "          y_genuine[genuine_count] = 1\n",
        "          genuine_count+=1\n",
        "    #for third set of fake pairs (using genuine and Face2Face_1)\n",
        "    for i in range (n):\n",
        "        for j in range (np-3):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/Face2Face_1/'+ face2face1_files[i][j])\n",
        "          x_fake_pair[fake_count, 0 ] = img1\n",
        "          x_fake_pair[fake_count, 1] = img2\n",
        "          y_fake[fake_count] = 0\n",
        "          fake_count+=1\n",
        "\n",
        "      #for fourth set of genuine pairs\n",
        "    for i in range (n):\n",
        "        for j in range (np-2):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j+2])\n",
        "          x_geuine_pair[genuine_count, 0 ] = img1\n",
        "          x_geuine_pair[genuine_count, 1] = img2\n",
        "          y_genuine[genuine_count] = 1\n",
        "          genuine_count+=1\n",
        "    #for fourth set of fake pairs (using genuine and Face2Face_2)\n",
        "    for i in range (n):\n",
        "        for j in range (np-2):\n",
        "          img1 = read_jpeg_image('path'+'/person' +str(i)+'/original/'+ original_files[i][j])\n",
        "          img2 = read_jpeg_image('path'+'/person' +str(i)+'/Face2Face_2/'+ face2face2_files[i][j])\n",
        "          x_fake_pair[fake_count, 0 ] = img1\n",
        "          x_fake_pair[fake_count, 1] = img2\n",
        "          y_fake[fake_count] = 0\n",
        "          fake_count+=1\n",
        "\n",
        "    #to concatenate, genuine pairs and fake pairs to get the whole data X and Y\n",
        "    X = np.concatenate([x_geuine_pair, x_fake_pair], axis=0)/255\n",
        "    Y = np.concatenate([y_genuine, y_fake], axis=0)\n",
        "    print(genuine_count)\n",
        "    print(fake_count)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vsgu9LJmMtUq"
      },
      "outputs": [],
      "source": [
        "#to get X and Y\n",
        "X, Y = get_data(total_sample_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Q4JTliSMwQm"
      },
      "outputs": [],
      "source": [
        "# to get the training and testing data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The VGG16 model using \"from tensorflow.keras.applications import VGG16\""
      ],
      "metadata": {
        "id": "2L62EYiZ6JCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogOCzxGQIft0"
      },
      "outputs": [],
      "source": [
        "def build_vgg16_base(input_shape):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    base = base_model.output\n",
        "    flat = Flatten()(base)\n",
        "    x = Dense(4096, activation='relu')(flat)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    dense = Dense(50, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=dense)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YXLoBukM_oT"
      },
      "outputs": [],
      "source": [
        "#to get the input shape\n",
        "input_shape = x_train.shape[2:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#base_network will be used in the siamese model\n",
        "base_network = build_vgg16_base(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "Ei7llJ1aPSaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the siamese model\n",
        "from keras.layers import concatenate\n",
        "img_a =  Input(shape=input_shape)\n",
        "img_b =  Input(shape=input_shape)\n",
        "img_a_feat = base_network(img_a)\n",
        "img_b_feat = base_network(img_b)\n",
        "#combined features\n",
        "combined_features = concatenate([img_a_feat, img_b_feat], name = 'merge_features')\n",
        "#dense layers, batchNormalization and sigmoid\n",
        "combined_features = Dense(100, activation = 'relu')(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(20, activation = 'relu')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
        "similarity_model = Model(inputs = [img_a, img_b], outputs = [combined_features], name = 'Similarity_Model')\n",
        "similarity_model.summary()"
      ],
      "metadata": {
        "id": "MTbvhtZm6e66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to compile the siamese model\n",
        "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy',tf.metrics.Recall(), tf.metrics.Precision()])"
      ],
      "metadata": {
        "id": "TaD5JkuZ1ERo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the inputs for the siamese model\n",
        "img_1 = x_train[:, 0]\n",
        "img_2 = x_train[:, 1]"
      ],
      "metadata": {
        "id": "c_xZGteQbwGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to train the siamese model\n",
        "loss_history =  similarity_model.fit([img_1, img_2], y_train,\n",
        "          batch_size=10, verbose=2, epochs=30)"
      ],
      "metadata": {
        "id": "vMtr8aT4b4IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3ksqLODQNSEG"
      },
      "outputs": [],
      "source": [
        "#to evaluate the siamese model\n",
        "pred = similarity_model.evaluate([x_test[:, 0], x_test[:, 1]], y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NH-aGxa0NTxJ"
      },
      "outputs": [],
      "source": [
        "#for siamese model prediction\n",
        "pred = similarity_model.predict([x_test[:, 0], x_test[:, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5WlC-J79Ncgy"
      },
      "outputs": [],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JcuJvAWeNecL"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "74Jd6w_Lgpog"
      },
      "outputs": [],
      "source": [
        "#importing the needed library\n",
        "from sklearn .metrics import roc_auc_score\n",
        "auc = np.round(roc_auc_score(y_test, pred), 3)\n",
        "print(\"Auc for our sample data is {}\".format(auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4M5wV7Xmgpoh"
      },
      "outputs": [],
      "source": [
        "#importing the needed libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U--_5YyLgpoi"
      },
      "outputs": [],
      "source": [
        "# to calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# to plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}